{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zillow House Price Prediction\n",
    "\n",
    "The following tackles the first round of [Zillow's Home Value Prediction Competition](https://www.kaggle.com/c/zillow-prize-1#description), which challenges competitors to predict the log error between Zillow's internal house price estimate (Zestimate) and the actual sale price of houses. The submissions are evaluated based on Mean Absolute Error between the predicted log error and the actual log error (see [here](https://www.kaggle.com/c/zillow-prize-1) for details). The competition was hosted from May 2017 to October 2017 on Kaggle, and the final private leaderboard was revealed after the evaluation period ended in January 2018.\n",
    "\n",
    "The score of the model in this repo would have ranked very high on the first round, and would qualified for the private second round, which involves building a home valuation algorithm from ground up.\n",
    "\n",
    "### Read Data\n",
    "\n",
    "The following imports libraries and reads the data, incl. external / derived features. \n",
    "\n",
    "The additional features were extracted using OpenStreetMap/OSMNX, NASA's Digital Elevation Model, US Census Data, and they include:\n",
    "* Number of several points of interest in a 500 meter radius around each property:\n",
    "    * Cafes and restaturants, \n",
    "    * Amenities (hospitals, fire_stations, schools, police stations)\n",
    "    * Roads & highways\n",
    "    * Public transport options (train stations, airports)\n",
    "    * Landscape (beach, hills, etc.)\n",
    "    * Historic monuments (castles, churches, monasteries, etc.)\n",
    "* The name of the nearest city.\n",
    "* The distance from the district's coordinates to the nearest city.\n",
    "* The population of the nearest city.\n",
    "* The nearest 'big city' (a big city is categorized as > 250,000 residents in the given year).\n",
    "* The distance to the nearest 'big city'.\n",
    "* Elevation of each property using NASA's Digital Elevation Model\n",
    "* Population density of the neighborhood each property is located in from the US Census Data using canpy\n",
    "\n",
    "See the *feature_extraction.ipynb* notebook for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mlflow\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "from xgboost.spark import SparkXGBRegressor as XGBoost\n",
    "\n",
    "from pyspark.ml.feature import (\n",
    "    VectorAssembler, FeatureHasher, OneHotEncoder, StringIndexer, Imputer \n",
    "    )\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "\n",
    "from src.reader import read\n",
    "import src.modelling as M\n",
    "\n",
    "# Spark configuration\n",
    "with open('./constants/config.json') as f   : config = json.load(f)\n",
    "with open('./constants/modelling.json') as f: const = json.load(f)\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.setMaster(config[\"spark_URL\"])\n",
    "conf.setAppName(config[\"app_name\"])\n",
    "[conf.set(key, value) for key, value in config[\"spark\"].items()]\n",
    "spark = SparkSession.builder.config(conf = conf).getOrCreate()\n",
    "\n",
    "# MLflow configuration\n",
    "mlflow.set_tracking_uri(uri = config[\"mlflow_URL\"])\n",
    "\n",
    "experimentID = M.makeExperiment(\n",
    "    name = config[\"app_name\"], \n",
    "    artifact_location = Path.cwd().joinpath(config[\"artifact_MLflow_dir\"]).as_uri()\n",
    "    )\n",
    "\n",
    "# Read data + extracted features and perform preprocessing\n",
    "df = read(spark, config[\"data\"], config[\"features_file\"])\n",
    "df = M.preprocess(df)\n",
    "\n",
    "dfTrain, dfTest = df.randomSplit(\n",
    "    weights = [const[\"train_ratio\"], 1 - const[\"train_ratio\"]], \n",
    "    seed    = const[\"seed\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyspark pipeline\n",
    "\n",
    "Setup the pipeline to perform the necessary preprocessing and hyperparameter tuning of XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gImputer  = M.GroupImputer(\n",
    "    inputCol   = M.const.GROUP_IMPUTER_IN, \n",
    "    outputCol  = M.const.GROUP_IMPUTER_OUT, \n",
    "    groupCol   = \"garagecarcnt\", \n",
    "    stochastic = bool(const[\"impute_stochastic\"])\n",
    "    )\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols  = M.const.IMPUTER_COLS, \n",
    "    outputCols = M.const.IMPUTER_COLS, \n",
    "    strategy   = const[\"impute_strategy\"]\n",
    "    )\n",
    "\n",
    "indexer = StringIndexer(\n",
    "    inputCols     = M.const.INDEX_IN, \n",
    "    outputCols    = M.const.INDEX_OUT, \n",
    "    handleInvalid = \"keep\"\n",
    "    )\n",
    "\n",
    "encoder = OneHotEncoder(\n",
    "    inputCols     = M.const.ONEHOT_IN, \n",
    "    outputCols    = M.const.ONEHOT_OUT, \n",
    "    handleInvalid = \"keep\"\n",
    "    )\n",
    "\n",
    "hasher = FeatureHasher(\n",
    "    inputCols = M.const.HASH_IN, \n",
    "    outputCol = M.const.HASH_OUT\n",
    "    )\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols     = M.const.ASSEMBLER_IN, \n",
    "    outputCol     = M.const.ASSEMBLER_OUT, \n",
    "    handleInvalid = \"keep\"\n",
    "    )\n",
    "\n",
    "regressor = XGBoost(\n",
    "    label_col      = M.const.TARGET_COL, \n",
    "    features_col   = M.const.ASSEMBLER_OUT, \n",
    "    prediction_col = M.const.PREDICTION_COL, \n",
    "    **M.const.XGB_CONSTANTS\n",
    "    )\n",
    "\n",
    "pipeline = Pipeline(stages = [gImputer, imputer, indexer, encoder, hasher, assembler, regressor]) \n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    predictionCol = M.const.PREDICTION_COL, \n",
    "    labelCol      = M.const.TARGET_COL, \n",
    "    metricName    = const[\"metric\"]\n",
    "    )\n",
    "\n",
    "h = const[\"hyperparameters\"]\n",
    "paramGrid = (\n",
    "    M.RandomGridBuilder(numIterations = const[\"num_search_iterations\"])\n",
    "    .addGrid(hasher.numFeatures,         lambda: np.random.choice(h[\"hasher_num_features\"]))\n",
    "    .addGrid(regressor.max_depth,        lambda: np.random.choice(h[\"xgb_max_depth\"]))\n",
    "    .addGrid(regressor.n_estimators,     lambda: np.random.choice(h[\"xgb_n_estimators\"]))\n",
    "    .addGrid(regressor.reg_lambda,       lambda: np.random.choice(h[\"xgb_reg_lambda\"]))\n",
    "    .addGrid(regressor.learning_rate,    lambda: np.random.choice(h[\"xgb_learning_rate\"]))\n",
    "    .addGrid(regressor.gamma,            lambda: np.random.choice(h[\"xgb_gamma\"]))\n",
    "    .addGrid(regressor.colsample_bytree, lambda: np.random.choice(h[\"xgb_colsample_bytree\"]))\n",
    "    .addGrid(regressor.max_leaves,       lambda: np.random.choice(h[\"xgb_max_leaves\"]))\n",
    "    .addGrid(regressor.subsample,        lambda: np.random.choice(h[\"xgb_subsample\"]))\n",
    "    .build()\n",
    ")\n",
    "\n",
    "crossval = CrossValidator(\n",
    "    estimatorParamMaps = paramGrid,\n",
    "    estimator = pipeline,\n",
    "    evaluator = evaluator,\n",
    "    numFolds  = const[\"num_folds\"])\n",
    "\n",
    "model = crossval.fit(dfTrain)\n",
    "\n",
    "M.logger(model, config[\"artifact_local_dir\"], experimentID, tags = None)\n",
    "\n",
    "results = model.transform(dfTest).select([\"logerror\", \"prediction\"]).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the error on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set MAE: 0.07484\n"
     ]
    }
   ],
   "source": [
    "actual    = results[\"logerror\"]\n",
    "predicted = results[\"prediction\"]\n",
    "mae = np.abs(actual - predicted).mean()\n",
    "\n",
    "print(f\"Test set MAE: {mae:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
